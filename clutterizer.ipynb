{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clutterizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhuZ7nZBasYLztPnjhf73h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psaboia/CV2_project/blob/main/clutterizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNU-zNpitjw8"
      },
      "source": [
        "# Nathan Vance's code with Jeremy Speth's and Priscila's changes.  \n",
        "import os\n",
        "import sys\n",
        "from os.path import isfile, join\n",
        "from os import listdir\n",
        "import math\n",
        "import random\n",
        "import json\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import transform\n",
        "from shapely.geometry import Polygon, LineString\n",
        "from scipy.ndimage.interpolation import rotate\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def sample_background(img_path):  \n",
        "  file_names = list(paths.list_images(img_path))\n",
        "  file_name = np.random.choice(file_names)\n",
        "  img = cv2.imread(file_name)  \n",
        "  return img\n",
        "\n",
        "def sample_objects(class_indivs, categories_dict, min_objects_per_image, max_objects_per_image):\n",
        "  num_objects = np.random.randint(min_objects_per_image,max_objects_per_image)\n",
        "  category_ids = list(categories_dict.keys())\n",
        "  obj_ids = np.random.choice(category_ids, num_objects, replace=False)\n",
        "  obj_list = [np.random.choice(class_indivs[obj_id]) for obj_id in obj_ids]\n",
        "  return obj_list, obj_ids    \n",
        "\n",
        "def load_coco_instances(json_path):\n",
        "\n",
        "  # load JSON\n",
        "  with open(json_path, 'r') as infile: data = json.load(infile)\n",
        "  # dictionary for images\n",
        "  images_dict = {i['id']: i['file_name'] for i in data['images']}\n",
        "  # dictionary for categories\n",
        "  categories_dict = {i['id']: i['name'] for i in data['categories']}\n",
        "  \n",
        "  # list of annotations by category_id\n",
        "  anno_list = {}\n",
        "  for anno in data['annotations']:\n",
        "      category_id = anno['category_id']\n",
        "      if category_id not in anno_list.keys():\n",
        "          anno_list[category_id] = [anno]\n",
        "      else:\n",
        "          anno_list[category_id].append(anno)\n",
        "\n",
        "  return anno_list, images_dict, categories_dict\n",
        "\n",
        "def plot_img(img, figsize=(5, 5)):\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.imshow(img)\n",
        "  # turns off axes\n",
        "  plt.axis(\"off\")\n",
        "  # gets rid of white border\n",
        "  plt.axis(\"tight\")\n",
        "  # square up the image instead of filling the \"figure\" space\n",
        "  plt.axis(\"image\")\n",
        "  plt.show()    \n",
        "  \n",
        "  #im_v = cv2.vconcat([img1, img1]) \n",
        "\n",
        "\n",
        "def get_annotation(mask, ann_id, image_id, category_id): \n",
        "\n",
        "  elem = {}\n",
        "  if np.sum(mask) > 0:\n",
        "    # for labeled mask\n",
        "    # label_temp[comb_label == obj_id+1] = (obj_id +1)*25\n",
        "\n",
        "    ## Writing json elements:      \n",
        "    # <ann_id> element\n",
        "    elem['id'] = ann_id\n",
        "\n",
        "    # <image_id> element\n",
        "    elem['image_id'] = image_id\n",
        "\n",
        "    # <category_id> element\n",
        "    elem['category_id'] = category_id\n",
        "\n",
        "    # - find segmented objects by using cv2.findContours \n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # - find the segmentation point list, list of boxes and total area\n",
        "    #   Note: If the object is occluded, it is possible that the object has  \n",
        "    #   been broken in non connected parts.\n",
        "    list_seg = []\n",
        "    list_pts = []\n",
        "    list_boxes = []\n",
        "    area = 0\n",
        "    for c in contours:\n",
        "      # - list of contours in the COCO format annotation for segmentation\n",
        "      points = np.array([[float(point[0][0]), float(point[0][1])] for point in c])\n",
        "      seg_points = np.hstack(points).tolist()\n",
        "      if len(seg_points) % 2 == 0 and len(seg_points) >= 6:\n",
        "        list_seg.append(seg_points)\n",
        "        area += cv2.contourArea(c)\n",
        "\n",
        "      # - list of boxes\n",
        "      (x, y, w, h) = cv2.boundingRect(c)\n",
        "      list_boxes.append([x,y, x+w,y+h])        \n",
        "\n",
        "    # <segmentation> element\n",
        "    elem['segmentation'] = list_seg\n",
        "\n",
        "    # <area> element\n",
        "    elem['area'] = int(area)\n",
        "\n",
        "    # <bbox> element\n",
        "    elem['bbox_mode'] = 1 # BoxMode.XYWH_ABS: 1 / BoxMode.XYXY_ABS: 0 \n",
        "    boxes = np.asarray(list_boxes)\n",
        "    x1, y1 = np.min(boxes, axis=0)[:2]\n",
        "    x2, y2 = np.max(boxes, axis=0)[2:]     \n",
        "    elem['bbox'] = [float(z) for z in [x1,y1,abs(x2-x1),abs(y2-y1)]]\n",
        "\n",
        "    # <iscrowd> element\n",
        "    elem['iscrowd'] = 0\n",
        "\n",
        "    # - show contours for debug \n",
        "    # im = mask.copy()\n",
        "    # im = cv2.drawContours(im, contours, -1, (0,0,255), 10)        \n",
        "    # im = cv2.rectangle(im,(x1,y1),(x2,y2),(255,0,0),5)\n",
        "    # cv2_imshow(im)\n",
        "    # plot_img(im, figsize=(10, 10))\n",
        "\n",
        "  return elem\n",
        "\n",
        "def add_annotations(annos, ann_id, image_id, obj_ids, obj_list, comb_label, mask):\n",
        "  for obj_id, obj in zip(obj_ids, obj_list):\n",
        "\n",
        "      # binary mask for the object\n",
        "      mask = (comb_label == (obj_id+1)).astype(np.uint8)\n",
        "      \n",
        "      # JSON annotation element for the object\n",
        "      \n",
        "      anno = get_annotation(mask, ann_id+1, image_id, obj['category_id'])\n",
        "      \n",
        "      if anno: \n",
        "        ann_id += 1\n",
        "        # add annotation\n",
        "        annos.append(anno)\n",
        "\n",
        "  return annos, ann_id\n",
        "\n",
        "def get_categories(categories_dict):\n",
        "  categories = []\n",
        "  for c in categories_dict:\n",
        "    elem_cat = {}\n",
        "    elem_cat['id'] = c\n",
        "    elem_cat['name'] = categories_dict[c] \n",
        "    categories.append(elem_cat)\n",
        "  return categories\n",
        "\n",
        "def get_image_dict(im_file_name, comb_width, comb_height):\n",
        "  im_dict = {}\n",
        "  im_dict['id'] = image_id\n",
        "  im_dict['file_name'] = im_file_name\n",
        "  im_dict['height'] = comb_height\n",
        "  im_dict['width'] = comb_width\n",
        "  return im_dict\n",
        "\n",
        "\n",
        "def add_obj_to_img(obj_img, obj_id, comb_image, comb_label):\n",
        "  comb_height, comb_width = comb_label.shape\n",
        "  img_height, img_width, _ = obj_img.shape\n",
        "  segm = np.array(obj['segmentation']).reshape(-1,2)\n",
        "\n",
        "  # plot_img(obj_img, figsize=(3, 3)) #cv2_imshow(obj_img)\n",
        "    \n",
        "  ### Rotate segmentation\n",
        "  rotation = np.random.uniform(0, 2*np.pi)\n",
        "  tform = transform.SimilarityTransform(rotation=rotation)\n",
        "  tform_mat = tform.params\n",
        "  segm_homog = np.append(segm, np.ones(len(segm)).reshape(-1, 1), 1)\n",
        "  segm_tformed = segm_homog.dot(tform_mat.T)[:,:2]\n",
        "\n",
        "  ### Shift it back to [0,0]\n",
        "  segm_tformed -= np.min(segm_tformed, 0)    \n",
        "\n",
        "  ### Pad image to scene size\n",
        "  pad_image = np.zeros((comb_height, comb_width, 3), dtype=np.uint8)\n",
        "  pad_image[:img_height, :img_width] = obj_img    \n",
        "  #cv2.imwrite(f'temp/{i}_{obj_id}_pad.jpg', pad_image)    \n",
        "\n",
        "  x1,y1 = segm_tformed.min(0)\n",
        "  x2,y2 = segm_tformed.max(0)\n",
        "  width = x2-x1\n",
        "  height = y2-y1\n",
        "  scale = np.random.uniform(0.20, 0.6)\n",
        "  translation = (np.random.randint(0, comb_width-(width*scale)), np.random.randint(0, comb_height-(height*scale)))\n",
        "  #translation = (np.random.randint(0, img_width-(width*scale)), np.random.randint(0, img_height-(height*scale)))\n",
        "\n",
        "\n",
        "  tform = transform.SimilarityTransform(scale=scale, translation=translation)\n",
        "  tform_mat = tform.params\n",
        "  segm_homog = np.append(segm_tformed, np.ones(len(segm_tformed)).reshape(-1, 1), 1)\n",
        "  segm_tformed = segm_homog.dot(tform_mat.T)[:,:2]\n",
        "\n",
        "\n",
        "  tform = transform.SimilarityTransform()\n",
        "  tform.estimate(segm, segm_tformed)\n",
        "  frame_tformed = transform.warp(pad_image, tform.inverse, preserve_range=True)\n",
        "  frame_tformed = frame_tformed.astype(np.uint8)\n",
        "  segm_tformed = segm_tformed.astype(np.int32)   \n",
        "  \n",
        "  # plot_img(frame_tformed, figsize=(3, 3))\n",
        "\n",
        "  segm_tformed[:,0] = np.clip(segm_tformed[:,0], 0, comb_width)\n",
        "  segm_tformed[:,1] = np.clip(segm_tformed[:,1], 0, comb_height)\n",
        "  segm_tformed = segm_tformed.reshape(-1,1,2).astype(np.int32)\n",
        "\n",
        "  mask = np.zeros(frame_tformed.shape[:3], dtype=np.uint8)     \n",
        "\n",
        "\n",
        "  # fill the ROI into the mask\n",
        "  #for point in segm_tformed:\n",
        "  #    mask = cv2.circle(mask, tuple(point[0]), 5, (0,255,0), -1)\n",
        "  cv2.fillPoly(mask, [segm_tformed], (1,1,1))\n",
        "\n",
        "  # The mask image\n",
        "  #cv2.imwrite(f'temp/{i}_{obj_id}_mask.jpg', mask*255)    \n",
        "  #plot_img( mask*255, figsize=(3, 3))\n",
        "\n",
        "  mask_gray = mask[:,:,0]\n",
        "  #contours, hierarchy = cv2.findContours(mask_gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  ### applying the mask to original image\n",
        "  masked_image = frame_tformed * mask\n",
        "\n",
        "  comb_image[mask==1] = frame_tformed[mask==1]\n",
        "  #comb_label[mask_gray==1] = obj_id*25\n",
        "  comb_label[mask_gray==1] = obj_id+1\n",
        "\n",
        "  #cv2.imwrite(f'temp/{i}_{obj_id}_masked.jpg', masked_image)\n",
        "  #cv2.imwrite(f'temp/{i}_{obj_id}_0.jpg', obj_image)\n",
        "  #cv2.imwrite(f'temp/{i}_{obj_id}_comb.jpg', comb_image)\n",
        "  #cv2.imwrite(f'temp/{i}_{obj_id}_label.jpg', comb_label)\n",
        "  #print()    \n",
        "\n",
        "  #plot_img( masked_image, figsize=(3, 3))\n",
        "  #plot_img( obj_img, figsize=(3, 3))\n",
        "  #plot_img( comb_image, figsize=(3, 3))\n",
        "  #plot_img( comb_label, figsize=(3, 3))\n",
        "\n",
        "  # cv2_imshow(comb_image)\n",
        "  return comb_image, comb_label, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nof-m7mNx1GO"
      },
      "source": [
        "from os.path import isfile, isdir, join\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UElIc6lmO02n"
      },
      "source": [
        "# Individual objects dataset path\n",
        "individual_objects_path = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_objects_v1/train\"\n",
        "individual_objects_json = join(individual_objects_path, \"annotations.json\")\n",
        "\n",
        "# Background images path\n",
        "img_bg_path = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/background\"\n",
        "\n",
        "# output path\n",
        "outdir = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/SyntheticClutteredObjects_v3\"\n",
        "if not os.path.isdir(outdir): os.makedirs(outdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yJuR7G74n-i"
      },
      "source": [
        "task_number = 50\n",
        "\n",
        "# seting up augmentation\n",
        "num_imgs = 10     # number of synthetic images to be generated\n",
        "min_obj = 9         # min number of objects per image\n",
        "max_obj = 10        # max number of objects per image\n",
        "synt_width = 3024   # width of the synthetic image\n",
        "synt_height = 3024  # height of the synthetic image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oK-yGFCnKODd"
      },
      "source": [
        "\n",
        "# Read a file containing JSON object on COCO format whith the individual object instances\n",
        "anno_list, images_dict, categories_dict = load_coco_instances(individual_objects_json)  \n",
        "\n",
        "start = task_number\n",
        "end = start + num_imgs\n",
        "size = (synt_height, synt_width)\n",
        "\n",
        "data = {}\n",
        "images = []\n",
        "annos = []\n",
        "ann_id = 0\n",
        "for image_id in tqdm(range(start, end)):\n",
        "  print(image_id)\n",
        "  # Choose sampling instances to form a cluttered synthetic image\n",
        "  obj_list, obj_ids = sample_objects(anno_list, categories_dict, min_obj, max_obj)\n",
        "\n",
        "  # Create an image to combine instances\n",
        "  comb_label = np.zeros((synt_height,synt_width), dtype=np.uint8) \n",
        "  background = sample_background(img_bg_path)\n",
        "  comb_image = cv2.resize(background, (synt_width, synt_height))\n",
        "  \n",
        "  for obj_id, obj in zip(obj_ids, obj_list):\n",
        "    print('obj_id ', obj_id, ' - ', categories_dict[obj_id], ' - ', images_dict[obj['image_id']])\n",
        "    obj_img = cv2.imread(join(individual_objects_path, images_dict[obj['image_id']]))\n",
        "  \n",
        "    comb_image, comb_label, mask = add_obj_to_img(obj_img, \n",
        "                                                  obj_id, \n",
        "                                                  comb_image, \n",
        "                                                  comb_label)\n",
        "    \n",
        "  \n",
        "  annos, ann_id = add_annotations(annos, ann_id, image_id, obj_ids, obj_list, comb_label, mask)\n",
        "\n",
        "\n",
        "  # Add image to the list of images\n",
        "  im_file_name = f'{image_id:04d}.jpg'\n",
        "  im_dict = get_image_dict(im_file_name, synt_width, synt_height)\n",
        "  images.append(im_dict)\n",
        "  # save image\n",
        "  cv2.imwrite(join(outdir, im_file_name), comb_image)\n",
        "  cv2_imshow(comb_image)\n",
        "\n",
        "# Add images to the main node data\n",
        "data['images'] = images\n",
        "\n",
        "# Add annotations to the main node data \n",
        "data['annotations'] = annos # get_annotations(obj_ids, obj_list, comb_label, mask, image_id)\n",
        "\n",
        "# Add categories to the main node data\n",
        "data['categories'] = get_categories(categories_dict)\n",
        "\n",
        "# write JSON\n",
        "json_path = join(outdir, \"annotations.json\")\n",
        "with open(json_path, 'w') as outfile:\n",
        "    json.dump(data, outfile)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}