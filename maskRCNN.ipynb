{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MaskRCNN_CV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP3rySesNIC+zad4Dkhw2zs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psaboia/CV2_project/blob/main/maskRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DELfjuIMe_wF"
      },
      "source": [
        "[Trying hyperparameters CV2 - T6]\n",
        "#**Occluded Object Detection with Scarce Data**\n",
        "\n",
        "## **MaskRCNN Experiment**\n",
        "\n",
        "Summary\n",
        "-------\n",
        "\n",
        "1.   Data loading\n",
        "  1.   Setting up infra\n",
        "  2.   Setting up the custom dataset\n",
        "2.   Trainnig\n",
        "  1.   Setting up Trainnig\n",
        "  2.   Performing trainnig\n",
        "  3.   Saving fine-tuned model\n",
        "3.   Evaluation & Inference (using the saved fine-tuned model)\n",
        "  1.   Validation set\n",
        "      1.   Evaluation using AP metric\n",
        "      2.   Inference\n",
        "  2.   Test set\n",
        "      1.   Inference\n",
        "      2.   Evaluation using AP metric\n",
        "            *   **Light**: ambient, **View**: side\n",
        "            *   **Light**: ambient, **View**: top\n",
        "            *   **Light**: side, **View**: side\n",
        "            *   **Light**: side, **View**: top\n",
        "            *   **Light**: top, **View**: side\n",
        "            *   **Light**: top, **View**: top\n",
        "  3.   Saving results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryQbyMqq5YdX"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvS2Yl6b5c-H"
      },
      "source": [
        "## Setting up infra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQf3I0TUSY2U"
      },
      "source": [
        "path_exp = '/content/drive/MyDrive/CSE/Spring21/cv2/task_2/models/exp3/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlEw4prfYWGE"
      },
      "source": [
        "## Step 1: Install Detectron2\n",
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for more instructions, if needed\n",
        "import torch\n",
        "assert torch.__version__.startswith(\"1.8\") # need to manually install torch 1.8 if Colab changes its default version\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "\n",
        "!pip install pillow==4.1.1\n",
        "%reload_ext autoreload\n",
        "%autoreload\n",
        "!pip install PIL\n",
        "!pip install image\n",
        "\n",
        "# Loading Detectron2 and other basic libraries, used later\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# Import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "import numpy as np\n",
        "def concat_imgs(im1,im2):\n",
        "  [h,w,d] = im1.shape\n",
        "  comp_im = np.ndarray(shape=(h,2*w,d), dtype=im1.dtype)\n",
        "  comp_im[:,:w,:] = im1\n",
        "  comp_im[:,w:,:] = im2\n",
        "  return comp_im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqE0yraI5lk_"
      },
      "source": [
        "## Setting up the custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEW9DgD3ceNN"
      },
      "source": [
        "## Step 2: Setting up dataset\n",
        "from os.path import isfile, isdir, join\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Prix dataset\n",
        "prix_dataset_train = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_objects_v3\"\n",
        "\n",
        "prix_dataset_val = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_objects_v1/val\"\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"prix_train\", {}, join(prix_dataset_train,\"annotations.json\"), prix_dataset_train)\n",
        "register_coco_instances(\"prix_val\", {}, join(prix_dataset_val,\"annotations.json\"), prix_dataset_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlF1QMQDdKA6"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv5juGS2dKa8"
      },
      "source": [
        "import random\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "import cv2\n",
        "\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "dataset_dicts = DatasetCatalog.get(\"prix_train\")\n",
        "prix_metadata = MetadataCatalog.get(\"prix_train\")\n",
        "\n",
        "for d in random.sample(dataset_dicts, 10):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=prix_metadata, scale=0.05)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfUGp6B-8AUb"
      },
      "source": [
        "# Trainnig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEz8jiBodS0S"
      },
      "source": [
        "## Setting up trainnig\n",
        "\n",
        "Creating a hook to compute our validation loss every few iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pprv9JDBKaXY"
      },
      "source": [
        "from detectron2.engine.hooks import HookBase\n",
        "from detectron2.evaluation import inference_context\n",
        "from detectron2.utils.logger import log_every_n_seconds\n",
        "from detectron2.data import DatasetMapper, build_detection_test_loader, build_detection_train_loader\n",
        "from detectron2.engine import DefaultTrainer\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.data import transforms as T\n",
        "from detectron2.data import detection_utils as utils\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "import logging\n",
        "import torch\n",
        "import time\n",
        "import datetime\n",
        "import copy\n",
        "\n",
        "\n",
        "\n",
        "class LossEvalHook(HookBase):\n",
        "    def __init__(self, eval_period, model, data_loader):\n",
        "        self._model = model\n",
        "        self._period = eval_period\n",
        "        self._data_loader = data_loader\n",
        "    \n",
        "    def _do_loss_eval(self):\n",
        "        # Copying inference_on_dataset from evaluator.py\n",
        "        total = len(self._data_loader)\n",
        "        num_warmup = min(5, total - 1)\n",
        "            \n",
        "        start_time = time.perf_counter()\n",
        "        total_compute_time = 0\n",
        "        losses = []\n",
        "        for idx, inputs in enumerate(self._data_loader):            \n",
        "\n",
        "            if idx == num_warmup:\n",
        "                start_time = time.perf_counter()\n",
        "                total_compute_time = 0\n",
        "            start_compute_time = time.perf_counter()\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "            total_compute_time += time.perf_counter() - start_compute_time\n",
        "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
        "            seconds_per_img = total_compute_time / iters_after_start\n",
        "\n",
        "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
        "\n",
        "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
        "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
        "                log_every_n_seconds(\n",
        "                    logging.INFO,\n",
        "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
        "                        idx + 1, total, seconds_per_img, str(eta)\n",
        "                    ),\n",
        "                    n=5,\n",
        "                )\n",
        "                \n",
        "            loss_batch = self._get_loss(inputs)\n",
        "            losses.append(loss_batch)\n",
        "        \n",
        "        mean_loss = np.mean(losses)\n",
        "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
        "        comm.synchronize()\n",
        "\n",
        "        return losses\n",
        "\n",
        "\n",
        "    def _get_loss(self, data):\n",
        "        # How loss is calculated on train_loop \n",
        "        metrics_dict = self._model(data)\n",
        "        metrics_dict = {\n",
        "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
        "            for k, v in metrics_dict.items()\n",
        "        }\n",
        "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
        "        return total_losses_reduced\n",
        "\n",
        "\n",
        "    def after_step(self):\n",
        "        next_iter = self.trainer.iter + 1\n",
        "        is_final = next_iter == self.trainer.max_iter\n",
        "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
        "            self._do_loss_eval()\n",
        "        self.trainer.storage.put_scalars(timetest=12)\n",
        "\n",
        "\n",
        "\n",
        "class MyTrainer(DefaultTrainer):\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        print(\"AQIOOOOOOOOOO \")        \n",
        "        train_augmentations = [\n",
        "            T.RandomBrightness(0.5, 2),\n",
        "            T.RandomContrast(0.5, 2),\n",
        "            T.RandomSaturation(0.5, 2),\n",
        "            T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
        "            T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
        "            T.RandomRotation(45, expand=False),\n",
        "            T.Resize((300, 300)),\n",
        "\n",
        "        ]        \n",
        "        return  build_detection_train_loader(cfg,mapper=DatasetMapper(cfg, is_train=True, augmentations=train_augmentations))\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
        "\n",
        "                     \n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.insert(-1, LossEvalHook(\n",
        "            cfg.TEST.EVAL_PERIOD,\n",
        "            self.model,\n",
        "            build_detection_test_loader(\n",
        "                self.cfg,\n",
        "                self.cfg.DATASETS.TEST[0],\n",
        "                DatasetMapper(self.cfg,True)\n",
        "            )\n",
        "        ))\n",
        "        return hooks       \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzZeoZ2gdeLC"
      },
      "source": [
        "## Performing training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1oJo8kXdgUe"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "\n",
        "selectedModel = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
        "\n",
        "cfg = get_cfg()\n",
        "preTrainedModel = selectedModel\n",
        "cfg.merge_from_file(model_zoo.get_config_file(preTrainedModel))\n",
        "\n",
        "# training\n",
        "cfg.DATASETS.TRAIN = (\"prix_train\",)\n",
        "\n",
        "# validation\n",
        "cfg.DATASETS.TEST = (\"prix_val\", )\n",
        "cfg.TEST.EVAL_PERIOD = 100\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        " \n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(preTrainedModel)\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64   # (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
        " \n",
        "# Solver options\n",
        "cfg.SOLVER.BASE_LR = 1e-3           # Base learning rate\n",
        "cfg.SOLVER.GAMMA = 0.5              # Learning rate decay\n",
        "cfg.SOLVER.STEPS = (250, 500, 750)  # Iterations at which to decay learning rate\n",
        "cfg.SOLVER.MAX_ITER = 1000          # Maximum number of iterations\n",
        "cfg.SOLVER.WARMUP_ITERS = 100       # Warmup iterations to linearly ramp learning rate from zero # adjust up if val mAP is still rising, adjust down if overfit\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1        # Lower to reduce memory usage (1 is the lowest)\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "# trainer = DefaultTrainer(cfg)     # will use the Detectron2 default trainer\n",
        "trainer = MyTrainer(cfg)            # will use our custom trainer that computes the validation losses too\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzsNeWVteG6F"
      },
      "source": [
        "## Saving fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xeb-AOreIbk"
      },
      "source": [
        "# Save model on my drive\n",
        "path_exp = '/content/drive/MyDrive/CSE/Spring21/cv2/task_2/models/exp3/'\n",
        "!cp -r output/ $path_exp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9w-T8_9lB00"
      },
      "source": [
        "# Evaluation & Inference (using the saved fine-tuned model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n-AsvPalIUj"
      },
      "source": [
        "---\n",
        "## Validation set (only objects)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jF1Yk826W35"
      },
      "source": [
        "### **Evaluation** using AP metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L61MJKVlD4J"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"prix_val\", )\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"prix_val\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"prix_val\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FOLr-0JlPAB"
      },
      "source": [
        "### **Inference**\n",
        "visualizing the prediction results on samples from the prix validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISOnNT6dlQA5"
      },
      "source": [
        "import numpy as np\n",
        "def concat_imgs(im1,im2):\n",
        "  [h,w,d] = im1.shape\n",
        "  comp_im = np.ndarray(shape=(h,2*w,d), dtype=im1.dtype)\n",
        "  comp_im[:,:w,:] = im1\n",
        "  comp_im[:,w:,:] = im2\n",
        "  return comp_im\n",
        "  \n",
        "# Inference\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "dataset_name = \"prix_val\"\n",
        "num_samples = 20\n",
        "\n",
        "for d in random.sample(DatasetCatalog.get(dataset_name), num_samples):        \n",
        "  im = cv2.imread(d[\"file_name\"])\n",
        "  outputs = predictor(im)\n",
        "      \n",
        "  # groundtruth image\n",
        "  visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get(dataset_name), scale=0.05)\n",
        "  vis_gt = visualizer.draw_dataset_dict(d)      \n",
        "  im_gt = vis_gt.get_image()[:, :, ::-1]\n",
        " \n",
        "  # predicted image\n",
        "  visualizer = Visualizer(im[:, :, ::-1], metadata=prix_metadata, scale=0.05)\n",
        "  vis_pr = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))            \n",
        "  im_pr = vis_pr.get_image()[:, :, ::-1]\n",
        "      \n",
        "  # show images\n",
        "  print(dataset_name + ' | ' + d[\"file_name\"].split('/')[-1])\n",
        "  cv2_imshow(concat_imgs(im_pr, im_gt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTAcq0lRldxi"
      },
      "source": [
        "---\n",
        "## Test set ( Uncluttered Tote Images)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjQ6D1Lo6twe"
      },
      "source": [
        "### **Inference**\n",
        "*Visualizing the prediction results on samples from the prix_uncluttered_tote unseen set*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ksrHrAld5d"
      },
      "source": [
        "# Import some common libraries\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import numpy as np\n",
        "def concat_imgs(im1,im2):\n",
        "  [h,w,d] = im1.shape\n",
        "  comp_im = np.ndarray(shape=(h,2*w,d), dtype=im1.dtype)\n",
        "  comp_im[:,:w,:] = im1\n",
        "  comp_im[:,w:,:] = im2\n",
        "  return comp_im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOFBJ7Cgcs4G"
      },
      "source": [
        "## Step 2: Setting up dataset\n",
        "from os.path import isfile, isdir, join\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGDZB_ZT609-"
      },
      "source": [
        "*Register coco instances => Tote images*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMUgRGg2613z"
      },
      "source": [
        "# Register coco instances\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "path_test_dataset = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_cluttered_objects_labelme\"\n",
        "list_dataset_name = listdir(path_test_dataset)\n",
        "\n",
        "for d in list_dataset_name:\n",
        "  register_coco_instances(d, {}, join(join(path_test_dataset, d),\"annotations.json\"), join(path_test_dataset, d))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akb9bBsY66eK"
      },
      "source": [
        "*Load Model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLbSKYUj66ny"
      },
      "source": [
        "# Load Model\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "# path_exp = '/content/drive/MyDrive/CSE/Spring21/cv2/Task_1/models/post_midterm_model/exp3/'\n",
        "path_exp = '/content/drive/MyDrive/CSE/Spring21/cv2/task_2/models/exp3/'\n",
        "\n",
        "path_model = join(path_exp, 'output')\n",
        "cfg = get_cfg() \n",
        "cfg.merge_from_file(model_zoo.get_config_file('COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml'))\n",
        "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1\n",
        "#cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.1 # 0.001# 0.01\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1\n",
        "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST =  0.001# 0.01\n",
        "\n",
        "cfg.MODEL.WEIGHTS = join(path_model, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTznw6zE69KN"
      },
      "source": [
        "*Inference*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Atclq9F69UM"
      },
      "source": [
        "# Inference\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "for dataset_name in list_dataset_name:\n",
        "  cfg.DATASETS.TEST = (dataset_name, )\n",
        "  dataset_dicts = DatasetCatalog.get(dataset_name)\n",
        "  tote_metadata = MetadataCatalog.get(dataset_name)\n",
        "\n",
        "  print(dataset_name)\n",
        "  n=10\n",
        "  scale = 0.3\n",
        "  for d in random.sample(dataset_dicts, n):        \n",
        "      im = cv2.imread(d[\"file_name\"])\n",
        "      outputs = predictor(im)\n",
        "      \n",
        "      # groundtruth image\n",
        "      visualizer = Visualizer(im[:, :, ::-1], metadata=tote_metadata, scale=scale)\n",
        "      vis_gt = visualizer.draw_dataset_dict(d)      \n",
        "      im_gt = vis_gt.get_image()[:, :, ::-1]\n",
        " \n",
        "      # predicted image\n",
        "      visualizer = Visualizer(im[:, :, ::-1], metadata=tote_metadata, scale=scale)\n",
        "      vis_pr = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))            \n",
        "      im_pr = vis_pr.get_image()[:, :, ::-1]\n",
        "      \n",
        "      # show images\n",
        "      print(dataset_name + ' | ' + d[\"file_name\"].split('/')[-1])\n",
        "      cv2_imshow(concat_imgs(im_pr, im_gt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z2rbmTZHb8XE"
      },
      "source": [
        "# Inference\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "print(dataset_name)\n",
        "n=5\n",
        "scale = 0.05\n",
        "for d in random.sample(dataset_dicts, n):        \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "\n",
        "    for k in range(10):\n",
        "      print(k, tote_metadata.thing_classes[k])\n",
        "      category_k_detections = instances[instances.pred_classes == k]\n",
        "        \n",
        "        ## FILTERS\n",
        "        # max score\n",
        "\n",
        "      cv2_imshow(im)\n",
        "      if len(category_k_detections) > 0:\n",
        "        confident_detection = category_k_detections[category_k_detections.scores == torch.max(category_k_detections.scores)]\n",
        "\n",
        "          # sort by score\n",
        "          # _, indices = torch.sort(category_k_detections.scores, descending=True)\n",
        "          # confident_detections = category_k_detections[indices]\n",
        "\n",
        "          # only highest than 's'\n",
        "          # s = 0.9\n",
        "          # confident_detections = category_k_detections[category_k_detections.scores > s]\n",
        "\n",
        "        visualizer = Visualizer(im[:, :, ::-1], metadata=tote_metadata, scale=scale)\n",
        "        vis_pr = visualizer.draw_instance_predictions(category_k_detections.to(\"cpu\"))            \n",
        "        x = vis_pr.get_image()[:, :, ::-1]\n",
        "\n",
        "\n",
        "        visualizer = Visualizer(im[:, :, ::-1], metadata=tote_metadata, scale=scale)\n",
        "        vis_pr = visualizer.draw_instance_predictions(confident_detection.to(\"cpu\"))            \n",
        "        y = vis_pr.get_image()[:, :, ::-1]\n",
        "\n",
        "        cv2_imshow(concat_imgs(x, y))\n",
        "\n",
        "      else:\n",
        "        print(\"No instance detected.\")  \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtcfrZps7FP4"
      },
      "source": [
        "### **Evaluation** using AP metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSFSpdQiz6b4"
      },
      "source": [
        "# Register coco instances\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "prix_dataset_test1 = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_objects_v1/test/light_ambient_vs\"\n",
        "prix_dataset_test2 = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_objects_v1/test/light_ambient_vt\"\n",
        "prix_dataset_test3 = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_objects_v1/test/light_side_vs\"\n",
        "prix_dataset_test4 = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_objects_v1/test/light_side_vt\"\n",
        "prix_dataset_test5 = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_objects_v1/test/light_top_vs\"\n",
        "prix_dataset_test6 = \"/content/drive/MyDrive/CSE/Spring21/cv2/dataset/prix_objects_v1/test/light_top_vt\"\n",
        "\n",
        "register_coco_instances(\"prix_test_1\", {}, join(prix_dataset_test1,\"annotations.json\"), prix_dataset_test1)\n",
        "register_coco_instances(\"prix_test_2\", {}, join(prix_dataset_test2,\"annotations.json\"), prix_dataset_test2)\n",
        "register_coco_instances(\"prix_test_3\", {}, join(prix_dataset_test3,\"annotations.json\"), prix_dataset_test3)\n",
        "register_coco_instances(\"prix_test_4\", {}, join(prix_dataset_test4,\"annotations.json\"), prix_dataset_test4)\n",
        "register_coco_instances(\"prix_test_5\", {}, join(prix_dataset_test5,\"annotations.json\"), prix_dataset_test5)\n",
        "register_coco_instances(\"prix_test_6\", {}, join(prix_dataset_test6,\"annotations.json\"), prix_dataset_test6)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4UVjbcyAF1P"
      },
      "source": [
        "# Load Model\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2   # set the testing threshold for this model\n",
        "\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX8XMqQt5iuS"
      },
      "source": [
        "---\n",
        "#### **Light**: ambient, **View**: side\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv0X3bkPyOt8"
      },
      "source": [
        "name_set = \"prix_test_1\"\n",
        "cfg.DATASETS.TEST = (name_set, )\n",
        "\n",
        "evaluator = COCOEvaluator(name_set, cfg, False, output_dir=\"./output/\"+name_set)\n",
        "val_loader = build_detection_test_loader(cfg, name_set)\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "\n",
        "#predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_LaW9C652Ld"
      },
      "source": [
        "\n",
        "---\n",
        "#### **Light**: ambient, **View**: top\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liA7V4VY2dVR"
      },
      "source": [
        "\n",
        "name_set = \"prix_test_2\"\n",
        "cfg.DATASETS.TEST = (name_set, )\n",
        "\n",
        "evaluator = COCOEvaluator(name_set, cfg, False, output_dir=\"./output/\"+name_set)\n",
        "val_loader = build_detection_test_loader(cfg, name_set)\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "\n",
        "#predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TDcf-dN6iqc"
      },
      "source": [
        "--- \n",
        "#### **Light**: side , **View**: side\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQqcSfEc6m06"
      },
      "source": [
        "name_set = \"prix_test_3\"\n",
        "cfg.DATASETS.TEST = (name_set, )\n",
        "\n",
        "evaluator = COCOEvaluator(name_set, cfg, False, output_dir=\"./output/\"+name_set)\n",
        "val_loader = build_detection_test_loader(cfg, name_set)\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "\n",
        "#predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66d4K0Fh6oe9"
      },
      "source": [
        "---\n",
        "#### **Light**: side, **View**: top\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovzuhq4t6om7"
      },
      "source": [
        "name_set = \"prix_test_4\"\n",
        "cfg.DATASETS.TEST = (name_set, )\n",
        "\n",
        "evaluator = COCOEvaluator(name_set, cfg, False, output_dir=\"./output/\"+name_set)\n",
        "val_loader = build_detection_test_loader(cfg, name_set)\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CROrFjfK6u1g"
      },
      "source": [
        "---\n",
        "#### **Light**: top, **View**: side\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq9HiIBvUVxT"
      },
      "source": [
        "name_set = \"prix_test_5\"\n",
        "cfg.DATASETS.TEST = (name_set, )\n",
        "\n",
        "evaluator = COCOEvaluator(name_set, cfg, False, output_dir=\"./output/\"+name_set)\n",
        "val_loader = build_detection_test_loader(cfg, name_set)\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "\n",
        "#predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCtdqrBR60m-"
      },
      "source": [
        "---\n",
        "#### **Light**: top, **View**: top\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kw8C7wQ60v9"
      },
      "source": [
        "name_set = \"prix_test_6\"\n",
        "cfg.DATASETS.TEST = (name_set, )\n",
        "\n",
        "evaluator = COCOEvaluator(name_set, cfg, False, output_dir=\"./output/\"+name_set)\n",
        "val_loader = build_detection_test_loader(cfg, name_set)\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "\n",
        "# predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9V6hqlmI4rT"
      },
      "source": [
        " ### Saving results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qom53HfhRb3r"
      },
      "source": [
        "# Save all results\n",
        "!cp -r output/ $path_exp"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}